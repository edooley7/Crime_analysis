{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from patsy import dmatrices\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pprint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"3355.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Condensing dataframe down to features to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df[[\n",
    "'CASENUM','YEAROB1','SEX','RACE','ETHNIC', \n",
    "'ADTYP','RELTYP','NFRCTNS',\n",
    "'DRUGTRT','ALCTRT','SEXTRT','EDUCAT','VOCAT',\n",
    "'SMPOFF5','RELAGE','SNTLN','TMSRV','PCTSRV',\n",
    "'A001CNT', 'A001YR','A001MO','A001ST','A001FM1', 'A001OFF1',\n",
    "'J001MO', 'J001YR', 'J001CNT', 'J001OFF1', 'J001FM1', 'J001CNV1', 'J001CNF1', 'J001PJP1', 'J001PMX1', 'J001PRB1',\n",
    "'REARR','ROTST','PRIR','POTST']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Replacing unknown numeric values with nan (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['YEAROB1'] = df2['YEAROB1'].replace(9999,np.nan)\n",
    "df2['A001YR'] = df2['A001YR'].replace(9999,np.nan)\n",
    "df2['A001YR'] = df2['A001YR'].replace(9998,np.nan)\n",
    "df2['REARR'] = df2['REARR'].replace(888,np.nan)\n",
    "df2['ROTST'] = df2['ROTST'].replace(888,np.nan)\n",
    "df2['PRIR'] = df2['PRIR'].replace(888,np.nan)\n",
    "df2['POTST'] = df2['POTST'].replace(888,np.nan)\n",
    "df2['RELAGE'] = df2['RELAGE'].replace(99999999.99,np.nan)\n",
    "df2['RELAGE'] = df2['RELAGE'].replace(100000000.00,np.nan)\n",
    "df2['TMSRV'] = df2['TMSRV'].replace(99899899.88,np.nan)\n",
    "df2['TMSRV'] = df2['TMSRV'].replace(998999.00,np.nan)\n",
    "df2['SNTLN'] = df2['SNTLN'].replace(99899899.88,np.nan)\n",
    "df2['SNTLN'] = df2['SNTLN'].replace(998999.00,np.nan)\n",
    "df2['PCTSRV'] = df2['PCTSRV'].replace(99899899.88,np.nan)\n",
    "df2['PCTSRV'] = df2['PCTSRV'].replace(998999.00,np.nan)\n",
    "df2['A001CNT'] = df2['A001CNT'].replace(99,np.nan)\n",
    "df2['A001CNT'] = df2['A001CNT'].replace(98,np.nan)\n",
    "df2['J001YR'] = df2['J001YR'].replace(9999,np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Adding calculated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['AGE_FIRST_OFF'] = df2.A001YR - df2.YEAROB1\n",
    "df2['AGE_FIRST_OFF'][df2['AGE_FIRST_OFF'] < 16] = np.nan\n",
    "df2['TOT_PRARR'] = (df2['PRIR'] + df2['POTST'])\n",
    "df2['CAREER_LEN'] = df2.RELAGE-df2.AGE_FIRST_OFF\n",
    "df2['SNTLN_YRS'] = df2.SNTLN/12\n",
    "df2['TOTREARR'] = df2.REARR + df2.ROTST\n",
    "df2['AVG_YRLY_ARR'] = df2.TOT_PRARR/df2.CAREER_LEN\n",
    "df2['AVG_YRLY_ARR'][df2['AVG_YRLY_ARR'] < 0] = np.nan\n",
    "df2['AVG_YRLY_ARR'][df2['AVG_YRLY_ARR'] > 100] = 0\n",
    "df2['RESP'] = 0\n",
    "df2['RESP'][df2['TOTREARR'] > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treatments = ['DRUGTRT', 'ALCTRT', 'SEXTRT', 'EDUCAT', 'VOCAT']\n",
    "\n",
    "for x in treatments:\n",
    "    df2[x] = df2[x].replace('UNKNOWN',0)\n",
    "    df2[x] = df2[x].replace('INMATE DID NOT PARTICIPATE',0)\n",
    "    df2[x] = df2[x].replace('INMATE PARTICIPATED BUT UNKNOWN IF COMPLETED',1)\n",
    "    df2[x] = df2[x].replace('INMATE PARTICIPATED IN PROGRAM & COMPLETED IT',1)\n",
    "    df2[x] = df2[x].replace('INMATE PARTICIPATED BUT DID NOT COMPLETE',1)\n",
    "\n",
    "df2['TREATMENT'] = df2.DRUGTRT + df2.ALCTRT + df2.SEXTRT + df2.EDUCAT + df2.VOCAT\n",
    "for x in treatments:\n",
    "    df2.drop(x, axis=1, inplace=True)\n",
    "df2['TREATMENT'][df2['TREATMENT'] > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Counting nan percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = df2.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    per = float(float(len(df2[feature]) - df2[feature].count())/len(df2[feature]))\n",
    "    if per > 0.0:\n",
    "        print feature, \"has %0.2f percent missing values\" % (per*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Cleaning up missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Hard coded the mode of the ROTST & POTST column\n",
    "df2['ROTST']= df2.ROTST.replace(np.nan,0)\n",
    "df2['POTST']= df2.POTST.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['PRIR'] = df2.PRIR.replace(np.nan,df2.PRIR.mean())\n",
    "df2['REARR'] = df2.REARR.replace(np.nan,df2.REARR.mean())\n",
    "df2['PCTSRV'] = df2.PCTSRV.replace(np.nan,df2.PCTSRV.mean())\n",
    "df2['TMSRV'] = df2.TMSRV.replace(np.nan,df2.TMSRV.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Recalculate features with cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['AGE_FIRST_OFF'] = df2.A001YR - df2.YEAROB1\n",
    "df2['AGE_FIRST_OFF'][df2['AGE_FIRST_OFF'] < 16] = np.nan\n",
    "df2['TOT_PRARR'] = (df2['PRIR'] + df2['POTST'])\n",
    "df2['CAREER_LEN'] = df2.RELAGE-df2.AGE_FIRST_OFF\n",
    "df2['SNTLN_YRS'] = df2.SNTLN/12\n",
    "df2['TOTREARR'] = df2.REARR + df2.ROTST\n",
    "df2['AVG_YRLY_ARR'] = df2.TOT_PRARR/df2.CAREER_LEN\n",
    "df2['AVG_YRLY_ARR'][df2['AVG_YRLY_ARR'] < 0] = np.nan\n",
    "df2['AVG_YRLY_ARR'][df2['AVG_YRLY_ARR'] > 100] = 0\n",
    "df2['RESP'] = 0\n",
    "df2['RESP'][df2['TOTREARR'] > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Recheck for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    per = float(float(len(df2[feature]) - df2[feature].count())/len(df2[feature]))\n",
    "    if per > 0.0:\n",
    "        print feature, \"has %0.2f percent missing values\" % (per*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Look at means for each group to be classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.groupby('RESP').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Quick visualize distribution of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_plot(x):\n",
    "    plt.figure(figsize = (15,5))\n",
    "    sns.countplot(sorted(df2[x]))\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.xlabel(x)\n",
    "    plt.show()\n",
    "\n",
    "for feature in features:\n",
    "    make_plot(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Set up selected features, train/test split and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ ADTYP + np.log(A001CNT+1) + SEX + RACE  + ETHNIC +RELTYP + J001PJP1+ np.log(RELAGE+1) + np.log(TMSRV+1) + np.log(TOT_PRARR+1) + PCTSRV + np.log(AGE_FIRST_OFF) + SMPOFF5+ A001FM1 + C(TREATMENT) + SNTLN_YRS + np.log(AVG_YRLY_ARR + 1)', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Baseline predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def always_reoffend(x):\n",
    "    return [1] * len(x)\n",
    "y_pred = always_reoffend(x_test)\n",
    "\n",
    "print \"Baseline = %0.2f\" % accuracy_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Train model and evaluate test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model(name, main_model):\n",
    "    model = main_model\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print name, \"test accuracy score:\", accuracy_score(y_test, model.predict(x_test))\n",
    "    \n",
    "test_model(\"KNN\", KNeighborsClassifier())\n",
    "test_model(\"Logistic Regression\", LogisticRegression())\n",
    "test_model(\"Gaussian Naive Bayes\", GaussianNB())\n",
    "test_model(\"SVM Classifier\", SVC())\n",
    "test_model(\"Decision Tree\", DecisionTreeClassifier())\n",
    "test_model(\"Random Forest\", RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Look at feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize = (25,10))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices)), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(len(indices)), X.columns[indices], rotation = 90)\n",
    "plt.xlim([-1, len(indices)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create dataframe with confusion matrix metrics for each feature in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm_features = ['AVG_YRLY_ARR','RELAGE','TOT_PRARR', 'TMSRV', 'AGE_FIRST_OFF','SNTLN_YRS', 'SMPOFF5','J001PJP1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_list = []\n",
    "for feature in cm_features:\n",
    "    model = \"y, X = dmatrices('RESP ~ \" +feature+ \"', data=df2, return_type='dataframe')\"\n",
    "    model_list.append(model)\n",
    "pprint.pprint(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ ADTYP + np.log(A001CNT+1) + SEX + RACE  + ETHNIC +RELTYP + J001PJP1+ np.log(RELAGE+1) + np.log(TMSRV+1) + np.log(TOT_PRARR+1) + PCTSRV + np.log(AGE_FIRST_OFF) + SMPOFF5+ A001FM1 + C(TREATMENT) + SNTLN_YRS + np.log(AVG_YRLY_ARR + 1)', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(np.hstack((cm[0],cm[1])))\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ TMSRV', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "cm_df['TMSRV'] = np.hstack((cm[0],cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ RELAGE', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "cm_df['RELAGE'] = np.hstack((cm[0],cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ SNTLN_YRS', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "cm_df['SNTLN_YRS'] = np.hstack((cm[0],cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ SMPOFF5', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "cm_df['SMPOFF5'] = np.hstack((cm[0],cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ A001CNT', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "cm_df['A001CNT'] = np.hstack((cm[0],cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ J001PJP1', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "cm_df['J001PJP1'] = np.hstack((cm[0],cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ TOT_PRARR', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "cm_df['TOT_PRARR'] = np.hstack((cm[0],cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ AVG_YRLY_ARR', data=df2, return_type='dataframe')\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "cm_df['AVG_YRLY_ARR'] = np.hstack((cm[0],cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('RESP ~ AGE_FIRST_OFF', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "cm_df['AGE_FIRST_OFF'] = np.hstack((cm[0],cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm_df.columns =['Full model', 'Time served (1994)', 'Age at release (1994)' , 'Sentence Length (1994)','Severity of offense (1994)', 'Consequence (first arrest)', 'Total prior arrests (1994)','Average arrest rate','Age at first offense',]\n",
    "cm_df =cm_df[['Full model', 'Time served (1994)', 'Age at release (1994)' , 'Sentence Length (1994)','Severity of offense (1994)','Consequence (first arrest)', 'Total prior arrests (1994)','Average arrest rate', 'Age at first offense']]\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm_plot_df = cm_df.T\n",
    "cm_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm_plot_df['Correct']= cm_plot_df[0] + cm_plot_df[3]\n",
    "cm_plot_df['Incorrect']= cm_plot_df[1] + cm_plot_df[2]\n",
    "cm_plot_df['Type 1']= cm_plot_df[1]\n",
    "cm_plot_df['Type 2']= cm_plot_df[2]\n",
    "cm_plot_df = cm_plot_df[['Correct', 'Incorrect','Type 1','Type 2']]\n",
    "cm_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "per_plot_df = cm_plot_df.copy()\n",
    "per_plot_df['TOTAL'] = per_plot_df['Correct'] + per_plot_df['Incorrect']\n",
    "per_plot_df['Correct'] = per_plot_df['Correct']/per_plot_df['TOTAL']\n",
    "per_plot_df['Incorrect'] = per_plot_df['Incorrect']/per_plot_df['TOTAL']\n",
    "per_plot_df = per_plot_df[['Correct', 'Incorrect']]\n",
    "per_plot_df = per_plot_df.sort(['Correct'], ascending = False)\n",
    "per_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "per_plot_df.to_csv('final_data.csv', sep=',', header = ['Correct', 'Incorrect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_per_plot_df = cm_plot_df.copy()\n",
    "in_per_plot_df['TOTAL'] = in_per_plot_df['Correct'] + in_per_plot_df['Incorrect']\n",
    "in_per_plot_df['Type 1'] = in_per_plot_df['Type 1']/in_per_plot_df['TOTAL']\n",
    "in_per_plot_df['Type 2'] = in_per_plot_df['Type 2']/in_per_plot_df['TOTAL']\n",
    "in_per_plot_df = in_per_plot_df[['Type 1', 'Type 2']]\n",
    "in_per_plot_df = in_per_plot_df.sort(['Type 1'], ascending = False)\n",
    "in_per_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_per_plot_df.to_csv('error_data.csv', sep=',', header = ['Innocent - presumed guilty', 'Guilty - presumed innocent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def curves(name, classifier):\n",
    "    probas_ = classifier.fit(x_train, y_train).predict_proba(x_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label = \"%s area under curve = %0.2f\" \n",
    "             % (name, roc_auc_score(y_test, probas_[:, 1])))\n",
    "    plt.legend(loc = \"best\")\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    #plt.title(\"ROC curves\")\n",
    "    \n",
    "curves(\"KNN\", KNeighborsClassifier())\n",
    "curves(\"Logistic Regression\", LogisticRegression())\n",
    "curves(\"Gaussian Naive Bayes\", GaussianNB())\n",
    "curves(\"SVM Classifier\", SVC(probability = True))\n",
    "curves(\"Decision Tree\", DecisionTreeClassifier())\n",
    "curves(\"Random Forest\", RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Grid search for best parameters for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"y, X = dmatrices('RESP ~ ADTYP + np.log(A001CNT+1) + SEX + RACE  + ETHNIC +RELTYP + J001PJP1+ np.log(RELAGE+1) + np.log(TMSRV+1) + np.log(TOT_PRARR+1) + PCTSRV + np.log(AGE_FIRST_OFF) + SMPOFF5+ A001FM1 + C(TREATMENT) + SNTLN_YRS + np.log(AVG_YRLY_ARR + 1)', data=df2, return_type='dataframe')\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=7)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train)\n",
    "x_test = std_scale.transform(x_test)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring='%s_weighted' % score)\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
